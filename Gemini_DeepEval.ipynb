{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e651c99a-fc6c-4b3e-927e-5b7dae9813fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG with Gemini Flash 1.5 LLM and DeepEval evaluation\n",
    "# Google Gemini: https://ai.google.dev/gemini-api/docs/models/gemini\n",
    "# DeepEval: https://docs.confident-ai.com/docs/guides-rag-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dafebe7-76cf-41d8-8734-0f06d15b9423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbdda733-b425-42f1-831a-6d71952ac5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "from llama_index.core import Document, VectorStoreIndex, Settings, StorageContext, load_index_from_storage\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "import pandas as pd\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90ecc13-1002-4dad-82e5-cf42b656718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dc3144c-2ac2-4448-a86a-a514ee26b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c3cd9fd-5949-4b1e-9894-c26618049ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724790441.369392   36018 check_gcp_environment.cc:61] BIOS data file does not exist or cannot be opened.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eab73af-ed30-4840-be7b-20eb1c66807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create document database\n",
    "# using 4 State of the Union speeches, all text from whitehouse.gov briefing room speeches posted online\n",
    "# Example from 2024:\n",
    "# https://www.whitehouse.gov/briefing-room/speeches-remarks/2024/03/07/remarks-of-president-joe-biden-state-of-the-union-address-as-prepared-for-delivery-2/\n",
    "sotu = []\n",
    "files = [\"./Speeches/state_of_the_union_042921.txt\", \"./Speeches/state_of_the_union_030122.txt\", \"./Speeches/state_of_the_union_020723.txt\", \"./Speeches/state_of_the_union_030724.txt\"]\n",
    "for i in files:\n",
    "    with open(i) as file:\n",
    "        for line in file:\n",
    "            nl = line.rstrip()\n",
    "            if nl != '':\n",
    "                sotu.append(nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fcdf1fa-c3c4-4f71-9585-a96bc9c02c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [Document(text=line) for line in sotu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab816039-1c34-4073-84a6-e57ad84832e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='ccf797b7-e2ce-4b9c-a660-35438f3d0a11', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='May God protect our troops.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of a loaded Document line\n",
    "documents[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41cce1c9-8df4-492b-9d15-18dd67cf3444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Set up the faiss index\n",
    "d = 768 # dimensions of ___, the embedding model that we're going to use\n",
    "faiss_index = faiss.IndexFlatL2(d)\n",
    "print(faiss_index.is_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e48c5f84-8fc4-4970-9505-3c67705b151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\") # optional: task_type=\"RETRIEVAL_DOCUMENT\"\n",
    "Settings.embed_model = doc_embeddings\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82ce1780-061d-4d6d-bf3c-6853db1eb4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment for when you need to re-embed and vectorize documents\n",
    "## otherwise, doing local loading below\n",
    "#vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "#storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "#index = VectorStoreIndex.from_documents(\n",
    "#    documents, storage_context=storage_context, show_progress=True\n",
    "#)\n",
    "## save index to disk\n",
    "#index.storage_context.persist()\n",
    "#index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77d046f3-293f-4bac-be0c-bedc5d88012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index from disk\n",
    "vector_store = FaissVectorStore.from_persist_dir(\"./storage\")\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store, persist_dir=\"./storage\"\n",
    ")\n",
    "index = load_index_from_storage(storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a1ba96f-37e3-4160-bf13-5536c2cbaf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(similarity_top_k=10)\n",
    "chat_engine = index.as_chat_engine(similarity_top_k=10, chat_mode='context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb6cee44-9396-41b0-b9f8-e6fd633fef55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amber/anaconda3/envs/research2/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseChatModel.predict_messages` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Example query and response\n",
    "query = \"What has the President done related to healthcare?\"\n",
    "response = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48698c67-efba-4fe3-a2e1-864a3f43131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The President has enacted several initiatives related to healthcare, including establishing a special sign-up period for the Affordable Care Act, enacting tax credits to reduce health care premiums, and re-igniting the Cancer Moonshot. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05980859-d7e3-44e8-bc4f-10a41fdd111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start of DeepEval implementation\n",
    "# https://docs.confident-ai.com/docs/guides-rag-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfebf282-9965-49bd-9c7f-d0e75e669b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research2",
   "language": "python",
   "name": "research2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
