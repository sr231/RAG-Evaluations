{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd552471-bc05-4749-b207-9be5e7e2d0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook uses the RAGAS evaluation library to evaluate several metrics for a RAG pipeline\n",
    "# I use the Google Gemini API (free tier, local API key), but RAGAS is compatible with several LLMs\n",
    "\n",
    "# Google Gemini: https://ai.google.dev/gemini-api/docs/models/gemini\n",
    "# RAGAS: https://docs.ragas.io/en/stable/\n",
    "# I used RAGAS v0.1.15 (mine was dev version from Github, but 0.1.15 from PyPI should work fine). \n",
    "\n",
    "# Note: I had to edit underlying RAGAS library (cloned locally, edited files, then pip -e installed locally) for this issue re: temperature with Gemini:\n",
    "# https://github.com/explodinggradients/ragas/pull/657/files\n",
    "# https://github.com/explodinggradients/ragas/issues/678\n",
    "# Edits simply remove the temperature variable from the relevant source files; see notes.txt for more specific info\n",
    "\n",
    "# RAGAS had a large redesign from version 0.1 to 0.2 : https://docs.ragas.io/en/stable/howtos/migrations/migrate_from_v01_to_v02/\n",
    "# - Note that on RAGAS version 0.2.6, the temperature edits did not make RAGAS compatible with Gemini.\n",
    "# - There are open Github issues about Gemini's compatibility for RAGAS version 2+; more time and edits would be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44922bc8-8feb-44cd-9541-84618200beb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAGAS metrics guide: https://docs.ragas.io/en/latest/concepts/metrics/index.html#ragas-metrics\n",
    "\n",
    "# Faithfulness - Measures the factual consistency of the answer to the context based on the question.\n",
    "# Context_precision - Measures how relevant the retrieved context is to the question, conveying the quality of the retrieval pipeline.\n",
    "# Answer_relevancy - Measures how relevant the answer is to the question.\n",
    "# Context_recall - Measures the retriever’s ability to retrieve all necessary information required to answer the question.\n",
    "\n",
    "# Faithfulness with HHEM - Similar to Faithfulness but uses a HuggingFace model (Vectara's HHEM 2.1 classifier) to detect hallucinations\n",
    "# https://docs.ragas.io/en/stable/concepts/metrics/faithfulness.html#faithfullness-with-hhem-2-1-model\n",
    "# https://huggingface.co/vectara/hallucination_evaluation_model\n",
    "\n",
    "# RAGAS has other metrics as well : https://docs.ragas.io/en/latest/concepts/metrics/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f13f959-5e0b-4e76-b116-da5da6a04ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set do not track variable for RAGAS\n",
    "# More info: https://github.com/explodinggradients/ragas/issues/49\n",
    "import os\n",
    "os.environ[\"RAGAS_DO_NOT_TRACK\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f30fd81d-ce93-4e03-bbec-862ece105b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import textwrap\n",
    "import ast\n",
    "import time\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Replace these two Google Gemini imports with imports for your LLM\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from llama_index.core import Document, VectorStoreIndex, Settings, StorageContext, load_index_from_storage\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "import faiss\n",
    "\n",
    "import ragas\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from ragas.run_config import RunConfig\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "from ragas import evaluate\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56373c08-f6b4-452a-8eba-63a20455d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b65e5d-d679-49c4-ade6-2719fecb55d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check the RAGAS do not track setting\n",
    "ragas._analytics.do_not_track()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ca08633-0877-4773-93ab-d4a78b8f5662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up local API key\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e22c5-2176-4d06-a69e-d1aa3eb23ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179c80c7-7695-4fa7-9b85-c48d949374d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish RAG pipeline with Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5248aab9-6fcd-46bf-b260-773c23b8845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a Faiss vector store for RAG\n",
    "# # If you already have an index created, skip a few coding cells to the LLM / embeddings setup\n",
    "\n",
    "# # Example of creating a small vector store\n",
    "# # Using 4 State of the Union speeches, all text from whitehouse.gov briefing room speeches posted online, edited to include a title with the date of the speech\n",
    "# # Example from 2024:\n",
    "# # https://www.whitehouse.gov/briefing-room/speeches-remarks/2024/03/07/remarks-of-president-joe-biden-state-of-the-union-address-as-prepared-for-delivery-2/\n",
    "\n",
    "# # load and parse files\n",
    "# sotu = []\n",
    "# newfiles = [\"./Speeches/titleedits/state_of_the_union_042921.txt\", \"./Speeches/titleedits/state_of_the_union_030122.txt\", \"./Speeches/titleedits/state_of_the_union_020723.txt\", \"./Speeches/titleedits/state_of_the_union_030724.txt\"]\n",
    "# for i in newfiles:\n",
    "#     with open(i) as file:\n",
    "#         for line in file:\n",
    "#             nl = line.rstrip()\n",
    "#             if nl != '':\n",
    "#                 sotu.append(nl)\n",
    "\n",
    "# # convert into Document format\n",
    "# documents = [Document(text=line) for line in sotu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fb9bf47-2a72-41a7-af8e-ae663bf95e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='235d1f3b-a216-412c-8459-51d27c73c8d0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='May God protect our troops.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Example of a loaded Document line\n",
    "# documents[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ed3997-3a20-4a99-a9c1-7cc6d6a217e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up the faiss index\n",
    "# d = 768 # dimensions of the input vector of the embedding model that we're going to use; in this case, the google embedding model\n",
    "# faiss_index = faiss.IndexFlatL2(d)\n",
    "# print(faiss_index.is_trained) # double check that the training worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "490599ac-6499-4174-999d-4ddc0609fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the llm, embeddings, and Settings for Faiss \n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\") # Replace with your LLM\n",
    "doc_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\") # Replace with your embeddings model\n",
    "Settings.embed_model = doc_embeddings # used for LlamaIndex FaissVectorStore\n",
    "Settings.llm = llm # used for LlamaIndex FaissVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c24d9337-5832-47d6-90df-6e73b3de8a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3171f73-723f-40f5-91d3-14e0f26173e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment for when you need to re-embed and vectorize documents\n",
    "\n",
    "# vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "# storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "# index = VectorStoreIndex.from_documents(\n",
    "#     documents, storage_context=storage_context, show_progress=True\n",
    "# )\n",
    "\n",
    "# # Save index to disk\n",
    "# index.storage_context.persist()\n",
    "\n",
    "# # Save/remember index id for loading next time\n",
    "# index.index_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60c8a330-0b12-434d-bc1c-4d8a7a1e32ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading llama_index.vector_stores.faiss.base from ./storage/default__vector_store.json.\n",
      "Loading llama_index.vector_stores.faiss.base from ./storage/default__vector_store.json.\n",
      "INFO:llama_index.core.indices.loading:Loading indices with ids: ['3d3c99c5-aa1c-42d7-a9ce-c4bb12fbc6d5']\n",
      "Loading indices with ids: ['3d3c99c5-aa1c-42d7-a9ce-c4bb12fbc6d5']\n"
     ]
    }
   ],
   "source": [
    "# After you have a saved index, load that index for RAG answer generation:\n",
    "\n",
    "# load index from disk\n",
    "vector_store = FaissVectorStore.from_persist_dir(\"./storage\")\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store, persist_dir=\"./storage\"\n",
    ")\n",
    "# My local index id '3d3c99c5-aa1c-42d7-a9ce-c4bb12fbc6d5' uses the 4 speeches including a title that includes the date it was given\n",
    "index = load_index_from_storage(storage_context=storage_context, index_id='3d3c99c5-aa1c-42d7-a9ce-c4bb12fbc6d5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ba1e938-d2bc-4ef3-a9d2-f2bc01a41e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional- if you'd like to query your index\n",
    "# # Set up query and chat engines with the index\n",
    "# query_engine = index.as_query_engine(similarity_top_k=10)\n",
    "# chat_engine = index.as_chat_engine(similarity_top_k=10, chat_mode='context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2026088c-515b-4933-9ec9-d3a616870533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example query and response with Gemini and query_engine\n",
    "# query = \"What has the President done related to healthcare?\"\n",
    "# response = query_engine.query(query) \n",
    "# print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0178b0-ee47-4443-b8fa-c5cb3b4de228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get ranked scores for top k RAG source nodes\n",
    "# for node in response.source_nodes:\n",
    "#     print(f\"{node.get_score()} -> {node.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0506d603-b9cb-43f1-b90b-99645cad7060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of using the chat engine with our index\n",
    "# query = \"You are an expert speech analyst and specialize in analyzing Presidential State of the Union speeches. Could you please analyze the speeches and generate 2 questions and answers from each speech, providing the document filename of each speech that relates to each question?\"\n",
    "# response = chat_engine.chat(query) \n",
    "# print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35114936-2d0c-4b06-99d7-16b4699d9388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional: View chat history\n",
    "# chat_engine.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf198ee7-45f6-4573-8bcb-60b25e2b7af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1f8b91f-afc2-4916-a65b-4a4bcb088d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for RAGAS evaluation library to work with Gemini and our local RAG setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af3f8028-582d-49b5-9939-45eb0d810501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of generating synthetic dataset with RAGAS\n",
    "\n",
    "# In a synthetic dataset, columns generated are 'question', 'contexts', 'ground_truth', 'evolution_type', 'metadata', and 'episode_done'\n",
    "# Ground truth is supposed to be the 'human' level answer vs the RAG answer\n",
    "\n",
    "# Notes: \n",
    "# - We have to generate the answer separately with our RAG, which then generates new context used.\n",
    "# - I use the context that was used to generate the answer for the metrics calculation, while still saving the old contexts column.\n",
    "# - The best thing to do would be to generate the answer when creating the synthetic test dataset, but this is not available in RAGAS.\n",
    "# - From a Github issue: Since you use the same LLM to generate your synthetic dataset ground_truth and your answer, \n",
    "# - it is possible the results of the RAG evaluation might be biased. This has not been studied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2002e239-4a5d-491d-b02b-611ae0f6afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents for use in generating synthetic dataset with RAGAS\n",
    "loader = DirectoryLoader(\"./Speeches/titleedits\") # Loads all docs in the directory; there are parameters for ignoring or matching certain files\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83aac065-04c4-46fc-baed-cdb9bf2d9825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to add 'filename' metadata for RAGAS to process documents\n",
    "for document in documents:\n",
    "    document.metadata['filename'] = document.metadata['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2b846e0-b319-4e00-ae3a-8796cb4be771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic testset generator with Gemini models\n",
    "generator_llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", timeout=240) # Other notable parameters: temperature=0.7, transport=\"rest\"\n",
    "critic_llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", timeout=240) \n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\", request_options={\"timeout\": 240}) \n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9cd22ec1-0bb5-4e12-8401-3866b2900d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the timeout settings with RAGAS's RunConfig class\n",
    "\n",
    "# Note: For Gemini, the RAGAS internal RunConfig settings do a decent job at limiting the 429 resource exhausted warnings\n",
    "# (max_workers=1 still can send more requests to Gemini than the 15 requests per minute it allows)\n",
    "# Still very difficult to have the testset generation run successfully with Gemini free tier\n",
    "# I also tried the ratelimit and backoff libraries in Python, but I still got so many 429 warnings that the generation failed\n",
    "# Sometimes even the 1 max worker will not finish, but it will finish occasionally\n",
    "\n",
    "run_config = RunConfig(timeout=240, max_retries=20, max_wait=240, max_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea76249e-a95d-421f-bc02-a290bbc94e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the synthetic dataset/testset\n",
    "def generate_testset_rate(docs):\n",
    "    \"\"\"\n",
    "    Calls the LLM and embeddings model to generate the synthetic dataset with rate limit run_config\n",
    "    Can change the distribution of simple, reasoning, and multi-context questions generated\n",
    "    \"\"\"\n",
    "    testset = generator.generate_with_langchain_docs(documents=documents, # LangChain source documents\n",
    "                                                     test_size=50, # number of test samples to generate\n",
    "                                                     distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25}, \n",
    "                                                     is_async=False,\n",
    "                                                     raise_exceptions=True, \n",
    "                                                     run_config=run_config)\n",
    "    return testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e6006a-7672-4bc2-80ee-af126e85d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = generate_testset_rate(documents=documents, run_config=run_config)  # edited to include run_config, ToDo: Test this\n",
    "testset_pd = testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87fd9f5e-145f-4f79-a430-07c32e5b7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save generated testset to csv \n",
    "# testset_pd.to_csv('datasets/testset_flash_pro15.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e411a9d-7aa3-4783-aa48-d6467a2b25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now generate answers for the testset, as answers are not automatically generated at creation\n",
    "\n",
    "# testset_pd = pd.read_csv(\"datasets/testset_flash_pro15.csv\", index_col = None)\n",
    "\n",
    "# Note: When saving, the 'contexts' column is saved as a string but needs to be a list\n",
    "# If you are importing testset_pd from a csv file, use the below code to change the column to a list\n",
    "\n",
    "# testset_pd['contexts'] = testset_pd['contexts'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dfd0ca-b9cd-4003-b6e3-addfc065a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate answers\n",
    "query_engine = index.as_query_engine(similarity_top_k=10)\n",
    "answers = [query_engine.query(q) for q in testset_pd['question']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33893af4-a200-4df9-9843-2e21a27d6e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse out new 'answer' and 'contexts' columns\n",
    "answers_new = []\n",
    "context_new = []\n",
    "for i in answers:\n",
    "    answers_new.append(i.response)\n",
    "    context_new.append([c.node.get_content() for c in i.source_nodes])\n",
    "\n",
    "testset_pd = testset_pd.rename(columns={\"contexts\":\"contexts_gt\"}) # Keeping old contexts that were used for testset/query generation (gt = ground truth)\n",
    "testset_pd['contexts'] = context_new\n",
    "testset_pd['answer'] = answers_new\n",
    "\n",
    "# Save complete synthetically created dataset/testset\n",
    "# testset_pd.to_csv('datasets/ragas_full_testset_flash_pro15.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fbfc8109-0336-43b4-bf49-1ed6142b5cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe228932-95ed-4d8c-a556-0bfac692fefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a dataset with RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7866f0b2-d32b-45af-8a91-7d77fbb0a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in dataset for evaluation\n",
    "testset_pd = pd.read_csv(\"datasets/unlabeled_dataset/unlabeled_dataset.csv\", index_col = None) \n",
    "\n",
    "# RAGAS expects the following columns (rename in dataset as needed) : \"question\", \"answer\", \"ground_truth\", \"source_file\", \"contexts\"\n",
    "# testset_pd = testset_pd.rename(columns={\"Query\": \"question\", \"Answer\": \"answer\", \"Expected_Output\": \"ground_truth\", \"Contexts\": \"orig_contexts\", \"Source_File\":\"source_file\", \"Document\": \"contexts\"})\n",
    "\n",
    "# Note: When saving, the 'contexts' column is saved as a string but needs to be a list\n",
    "# If you are importing testset_pd from a csv file, use the below code to change the column to a list\n",
    "# testset_pd['contexts'] = testset_pd['contexts'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd8adaf0-d20c-4d55-b25e-73b84da5b063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>orig_contexts</th>\n",
       "      <th>source_file</th>\n",
       "      <th>contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Identify specific examples of government inves...</td>\n",
       "      <td>The transcontinental railroad and the intersta...</td>\n",
       "      <td>The speech highlights several examples: the tr...</td>\n",
       "      <td>; discovering vaccines; gave us the Internet a...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_042921.txt</td>\n",
       "      <td>[Throughout our history, if you think about it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Does the American Jobs Plan, a large-scale inv...</td>\n",
       "      <td>The plan seeks to create jobs by modernizing i...</td>\n",
       "      <td>The American Jobs Plan aims to create jobs by ...</td>\n",
       "      <td>; discovering vaccines; gave us the Internet a...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_042921.txt</td>\n",
       "      <td>[The American Jobs Plan creates jobs replacing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Considering the significant impact of cancer o...</td>\n",
       "      <td>Investing in cancer research is a priority bec...</td>\n",
       "      <td>Investing in cancer research is a priority bec...</td>\n",
       "      <td>But so many of us have deceased sons, daughter...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_042921.txt</td>\n",
       "      <td>[But so many of us have deceased sons, daughte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the President's viewpoint on infrastr...</td>\n",
       "      <td>The President believes that infrastructure inv...</td>\n",
       "      <td>The President emphasizes that infrastructure i...</td>\n",
       "      <td>But so many of us have deceased sons, daughter...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_042921.txt</td>\n",
       "      <td>[Investments in jobs and infrastructure, like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Analyze the potential economic consequences of...</td>\n",
       "      <td>A progressive tax structure, where higher earn...</td>\n",
       "      <td>The President advocates for raising taxes on c...</td>\n",
       "      <td>you should be able to become a billionaire an...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_042921.txt</td>\n",
       "      <td>[When you hear someone say that they don’t wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>Explain how the president's call for aid to Ga...</td>\n",
       "      <td>The president emphasizes the importance of inc...</td>\n",
       "      <td>The president's call for aid to Gaza is direct...</td>\n",
       "      <td>I say we must stop it.  \\n\\nI’m proud we beat ...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_030724.txt</td>\n",
       "      <td>[Tonight, I’m directing the U.S. military to l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>If a ceasefire were to fail, how would the Pre...</td>\n",
       "      <td>The President's proposed humanitarian efforts ...</td>\n",
       "      <td>The President's proposal for a temporary pier ...</td>\n",
       "      <td>I say we must stop it.  \\n\\nI’m proud we beat ...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_030724.txt</td>\n",
       "      <td>[Tonight, I’m directing the U.S. military to l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>What steps is the US President taking to achie...</td>\n",
       "      <td>The US President is directing the military to ...</td>\n",
       "      <td>The US President is working to achieve a cease...</td>\n",
       "      <td>I say we must stop it.  \\n\\nI’m proud we beat ...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_030724.txt</td>\n",
       "      <td>[Tonight, I’m directing the U.S. military to l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Identify the central theme of the President's ...</td>\n",
       "      <td>The President strongly advocates for reproduct...</td>\n",
       "      <td>The President's opening remarks regarding repr...</td>\n",
       "      <td>no place in America! \\n\\nHistory is watching....</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_030724.txt</td>\n",
       "      <td>[Like most Americans, I believe Roe v. Wade go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>Analyze the speech's rhetorical strategies in ...</td>\n",
       "      <td>The speech employs several rhetorical strategi...</td>\n",
       "      <td>The speech uses several rhetorical strategies ...</td>\n",
       "      <td>no place in America! \\n\\nHistory is watching....</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_030724.txt</td>\n",
       "      <td>[In its decision to overturn Roe v. Wade the S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Identify specific examples of government inves...   \n",
       "1    Does the American Jobs Plan, a large-scale inv...   \n",
       "2    Considering the significant impact of cancer o...   \n",
       "3    How does the President's viewpoint on infrastr...   \n",
       "4    Analyze the potential economic consequences of...   \n",
       "..                                                 ...   \n",
       "795  Explain how the president's call for aid to Ga...   \n",
       "796  If a ceasefire were to fail, how would the Pre...   \n",
       "797  What steps is the US President taking to achie...   \n",
       "798  Identify the central theme of the President's ...   \n",
       "799  Analyze the speech's rhetorical strategies in ...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    The transcontinental railroad and the intersta...   \n",
       "1    The plan seeks to create jobs by modernizing i...   \n",
       "2    Investing in cancer research is a priority bec...   \n",
       "3    The President believes that infrastructure inv...   \n",
       "4    A progressive tax structure, where higher earn...   \n",
       "..                                                 ...   \n",
       "795  The president emphasizes the importance of inc...   \n",
       "796  The President's proposed humanitarian efforts ...   \n",
       "797  The US President is directing the military to ...   \n",
       "798  The President strongly advocates for reproduct...   \n",
       "799  The speech employs several rhetorical strategi...   \n",
       "\n",
       "                                          ground_truth  \\\n",
       "0    The speech highlights several examples: the tr...   \n",
       "1    The American Jobs Plan aims to create jobs by ...   \n",
       "2    Investing in cancer research is a priority bec...   \n",
       "3    The President emphasizes that infrastructure i...   \n",
       "4    The President advocates for raising taxes on c...   \n",
       "..                                                 ...   \n",
       "795  The president's call for aid to Gaza is direct...   \n",
       "796  The President's proposal for a temporary pier ...   \n",
       "797  The US President is working to achieve a cease...   \n",
       "798  The President's opening remarks regarding repr...   \n",
       "799  The speech uses several rhetorical strategies ...   \n",
       "\n",
       "                                         orig_contexts  \\\n",
       "0    ; discovering vaccines; gave us the Internet a...   \n",
       "1    ; discovering vaccines; gave us the Internet a...   \n",
       "2    But so many of us have deceased sons, daughter...   \n",
       "3    But so many of us have deceased sons, daughter...   \n",
       "4     you should be able to become a billionaire an...   \n",
       "..                                                 ...   \n",
       "795  I say we must stop it.  \\n\\nI’m proud we beat ...   \n",
       "796  I say we must stop it.  \\n\\nI’m proud we beat ...   \n",
       "797  I say we must stop it.  \\n\\nI’m proud we beat ...   \n",
       "798   no place in America! \\n\\nHistory is watching....   \n",
       "799   no place in America! \\n\\nHistory is watching....   \n",
       "\n",
       "                                           source_file  \\\n",
       "0    Speeches/titleedits/state_of_the_union_042921.txt   \n",
       "1    Speeches/titleedits/state_of_the_union_042921.txt   \n",
       "2    Speeches/titleedits/state_of_the_union_042921.txt   \n",
       "3    Speeches/titleedits/state_of_the_union_042921.txt   \n",
       "4    Speeches/titleedits/state_of_the_union_042921.txt   \n",
       "..                                                 ...   \n",
       "795  Speeches/titleedits/state_of_the_union_030724.txt   \n",
       "796  Speeches/titleedits/state_of_the_union_030724.txt   \n",
       "797  Speeches/titleedits/state_of_the_union_030724.txt   \n",
       "798  Speeches/titleedits/state_of_the_union_030724.txt   \n",
       "799  Speeches/titleedits/state_of_the_union_030724.txt   \n",
       "\n",
       "                                              contexts  \n",
       "0    [Throughout our history, if you think about it...  \n",
       "1    [The American Jobs Plan creates jobs replacing...  \n",
       "2    [But so many of us have deceased sons, daughte...  \n",
       "3    [Investments in jobs and infrastructure, like ...  \n",
       "4    [When you hear someone say that they don’t wan...  \n",
       "..                                                 ...  \n",
       "795  [Tonight, I’m directing the U.S. military to l...  \n",
       "796  [Tonight, I’m directing the U.S. military to l...  \n",
       "797  [Tonight, I’m directing the U.S. military to l...  \n",
       "798  [Like most Americans, I believe Roe v. Wade go...  \n",
       "799  [In its decision to overturn Roe v. Wade the S...  \n",
       "\n",
       "[800 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d735bf4-b628-4b08-b504-61c67b137d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At least for RAGAS v0.1.15, we need to convert the pandas testset into Dataset format for the evaluate function to work\n",
    "# Note: I am also dropping the original contexts column here\n",
    "testset_ds = Dataset.from_pandas(testset_pd.drop(\"orig_contexts\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "104fced3-164c-44df-a0b2-55e953d33d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'ground_truth', 'source_file', 'contexts'],\n",
       "    num_rows: 800\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a39ae55f-204a-4b42-8811-710bd26502cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: I'm using the normal LLM, not the RAG context-loaded query engine\n",
    "# There is code at the bottom of the notebook for using the query engine, which should be the way to go\n",
    "# However, that code appears to be broken from RAGAS right now, so I was forced to use the regular Gemini LLM\n",
    "\n",
    "# Note: The RAGAS evaluate function (below) may re-run the query and give new answers and contexts\n",
    "# See this issue: https://github.com/explodinggradients/ragas/issues/1211\n",
    "# In testing, the results still give me the same answers and contexts as I started with, so I'm not concerned by this\n",
    "\n",
    "ragas_llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", timeout=600) # try request_timeout=120\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47977c82-14b7-4291-9b53-3c9ce0510487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the timeout settings\n",
    "run_config = RunConfig(timeout=300, max_wait=3000, max_workers=1, max_retries=10)  # Increase timeout to 180 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d845d9f-6d08-4fde-8ded-361b7d12e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional parameter: \n",
    "# in_ci: bool, Whether the evaluation is running in CI or not. \n",
    "# If set to True then some metrics will be run to increase the reproducability of the evaluations. \n",
    "# This will increase the runtime and cost of evaluations. Default is False.\n",
    "# In practice, setting in_ci = True resulted in a lot of timeouts / no score calculated / NaN\n",
    "evalresult = evaluate(\n",
    "    metrics = [\n",
    "        context_precision\n",
    "        #faithfulness,\n",
    "        #answer_relevancy,\n",
    "        #context_recall\n",
    "    ],\n",
    "    dataset = testset_ds,\n",
    "    llm = ragas_llm,\n",
    "    embeddings=embeddings,\n",
    "    run_config=run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75a03c5c-b6a2-4a15-9d62-b9a6890dcd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_precision': 0.3405}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalresult # original batch run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "494b292a-c1e2-4da7-a737-9adb5267fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalresult.to_pandas().to_csv(\"results/evalresult.csv\") # original batch run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "754fd8e8-7912-45dc-82a0-a8ace8103f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalresults = pd.read_csv(\"results/evalresult.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8b35517-0b73-4836-b9c0-834ec7144ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalresults['context_precision'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b851250-416b-42d8-bb28-daa1e674a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not documented that I could find, discovered in github issue\n",
    "# evalresult.to_pandas() will give sample-level scores!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d5ecd8cf-8642-4ea0-ac1a-c6bcbb05a621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_precision': 0.5979, 'faithfulness': 1.0000, 'answer_relevancy': 0.6533, 'context_recall': 0.8000}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example result:\n",
    "# {'context_precision': 0.4676, 'faithfulness': 1.0000, 'answer_relevancy': 0.6515, 'context_recall': 0.8000}\n",
    "# Reran\n",
    "# {'context_precision': 0.5979, 'faithfulness': 1.0000, 'answer_relevancy': 0.6533, 'context_recall': 0.8000}\n",
    "evalresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31c0353a-43a2-4d9a-9738-e598a512ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdataset = testset_ds.select(range(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "878142ef-d792-4fb6-858a-b4e62d99fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d028c995-132f-4ce8-bca5-c4b981d5ee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17709e07-b809-4342-be28-33e65503ad7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b665b415154d228650673bd868e569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "741\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e914be34054e68bcf408208061c490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d14da40932146c08019737af67d1d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "743\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e575091d5c44c84b18ce1c5a0e3237b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b6c3a587e24dea9e3e6ff326b9f79e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aca9eb3906c4eb18761292f96aeaf3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edeefee93ab846c1a3c9b7c54230137e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    }
   ],
   "source": [
    "# ToDo: let this run (in batches) over the entire dataset next time if evaluate call on entire dataset doesn't work\n",
    "# Optional parameter: \n",
    "# in_ci: bool, Whether the evaluation is running in CI or not. \n",
    "# If set to True then some metrics will be run to increase the reproducibility of the evaluations. \n",
    "# This will increase the runtime and cost of evaluations. Default is False.\n",
    "# In practice, setting in_ci = True resulted in a lot of timeouts / no score calculated / NaN\n",
    "# Stopped 12/2 0-147, 12/3: 147-297, 12/4: 297-447, 12/5: 448-598, 12/6: 447-448, 598-747\n",
    "for i in range(740,747):\n",
    "    tempdataset = testset_ds.select(range(i, i+1))\n",
    "    print(i)\n",
    "    evalresult = evaluate(\n",
    "        metrics = [\n",
    "            context_precision\n",
    "            #faithfulness,\n",
    "            #answer_relevancy,\n",
    "            #context_recall\n",
    "        ],\n",
    "        dataset = tempdataset,\n",
    "        llm = ragas_llm,\n",
    "        embeddings=embeddings,\n",
    "        run_config=run_config\n",
    "    )\n",
    "    scores.append(evalresult['context_precision'])\n",
    "    testset_results = pd.concat([testset_results, evalresult.to_pandas()])\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6e7c682-63e1-4ea6-95e0-46d03a9600c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>source_file</th>\n",
       "      <th>contexts</th>\n",
       "      <th>context_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compare the American Jobs Plan with the Americ...</td>\n",
       "      <td>The American Jobs Plan focuses on creating job...</td>\n",
       "      <td>The American Jobs Plan focuses on infrastructu...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_042921.txt</td>\n",
       "      <td>[Look, the American Jobs Plan will help millio...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Compare the American Jobs Plan with the Americ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The American Jobs Plan focuses on creating job...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  The American Jobs Plan focuses on infrastructu...   \n",
       "\n",
       "                                         source_file  \\\n",
       "0  Speeches/titleedits/state_of_the_union_042921.txt   \n",
       "\n",
       "                                            contexts  context_precision  \n",
       "0  [Look, the American Jobs Plan will help millio...                0.0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalresult.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74b52fea-6b24-4f62-ad8b-9f5b1c26ff12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.359384\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testset_results = pd.concat([testset_results, evalresult.to_pandas()])\n",
    "pd.DataFrame(scores, index=None).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82821798-13d6-4460-b133-14aa15a415e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b6078a4-c8de-46bd-9b0e-9885cc6625a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>source_file</th>\n",
       "      <th>contexts</th>\n",
       "      <th>context_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compare the author's position on cutting Socia...</td>\n",
       "      <td>The author strongly opposes any cuts to Social...</td>\n",
       "      <td>The author firmly opposes any cuts to Social S...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_020723.txt</td>\n",
       "      <td>[Instead of making the wealthy pay their fair ...</td>\n",
       "      <td>0.770833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Considering the reduction of the deficit, the ...</td>\n",
       "      <td>The administration has achieved significant re...</td>\n",
       "      <td>The administration has achieved significant pr...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_020723.txt</td>\n",
       "      <td>[In the last two years, my administration cut ...</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is it fair that the administration is proposin...</td>\n",
       "      <td>The administration believes it is fair to incr...</td>\n",
       "      <td>The President believes that the wealthy and co...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_020723.txt</td>\n",
       "      <td>[And we pay for these investments in our futur...</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyze the rhetorical strategies employed by ...</td>\n",
       "      <td>The speaker uses powerful rhetoric to galvaniz...</td>\n",
       "      <td>The speaker employs several rhetorical strateg...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_030724.txt</td>\n",
       "      <td>[My fellow Americans the issue facing our nati...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How might these policies, if implemented, impa...</td>\n",
       "      <td>The policies described aim to shift the distri...</td>\n",
       "      <td>These policies, if implemented, could have a s...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_030724.txt</td>\n",
       "      <td>[America’s comeback is building a future of Am...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was the deadliest day for the Jewish peop...</td>\n",
       "      <td>Empty Response</td>\n",
       "      <td>October 7th, when Hamas slaughtered 1,200 inno...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_030724.txt</td>\n",
       "      <td>[The deadliest day for the Jewish people since...</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compare the US President's efforts to establis...</td>\n",
       "      <td>The US President is actively working to establ...</td>\n",
       "      <td>The US President is working to establish an im...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_030724.txt</td>\n",
       "      <td>[Israel has an added burden because Hamas hide...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How has the speaker addressed the affordabilit...</td>\n",
       "      <td>The speaker has addressed the affordability of...</td>\n",
       "      <td>The speaker has addressed the affordability of...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_030724.txt</td>\n",
       "      <td>[Let’s continue increasing Pell Grants for wor...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarize the speaker's proposals for making t...</td>\n",
       "      <td>The speaker proposes several measures to make ...</td>\n",
       "      <td>The speaker proposes raising the minimum tax r...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_030724.txt</td>\n",
       "      <td>[The way to make the tax code fair is to make ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compare the economic state of the nation befor...</td>\n",
       "      <td>The speaker highlights a significant improveme...</td>\n",
       "      <td>The president highlights that the economy was ...</td>\n",
       "      <td>Speeches/titleedits/state_of_the_union_030724.txt</td>\n",
       "      <td>[I inherited an economy that was on the brink....</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   Compare the author's position on cutting Socia...   \n",
       "0   Considering the reduction of the deficit, the ...   \n",
       "0   Is it fair that the administration is proposin...   \n",
       "0   Analyze the rhetorical strategies employed by ...   \n",
       "0   How might these policies, if implemented, impa...   \n",
       "..                                                ...   \n",
       "0   What was the deadliest day for the Jewish peop...   \n",
       "0   Compare the US President's efforts to establis...   \n",
       "0   How has the speaker addressed the affordabilit...   \n",
       "0   Summarize the speaker's proposals for making t...   \n",
       "0   Compare the economic state of the nation befor...   \n",
       "\n",
       "                                               answer  \\\n",
       "0   The author strongly opposes any cuts to Social...   \n",
       "0   The administration has achieved significant re...   \n",
       "0   The administration believes it is fair to incr...   \n",
       "0   The speaker uses powerful rhetoric to galvaniz...   \n",
       "0   The policies described aim to shift the distri...   \n",
       "..                                                ...   \n",
       "0                                      Empty Response   \n",
       "0   The US President is actively working to establ...   \n",
       "0   The speaker has addressed the affordability of...   \n",
       "0   The speaker proposes several measures to make ...   \n",
       "0   The speaker highlights a significant improveme...   \n",
       "\n",
       "                                         ground_truth  \\\n",
       "0   The author firmly opposes any cuts to Social S...   \n",
       "0   The administration has achieved significant pr...   \n",
       "0   The President believes that the wealthy and co...   \n",
       "0   The speaker employs several rhetorical strateg...   \n",
       "0   These policies, if implemented, could have a s...   \n",
       "..                                                ...   \n",
       "0   October 7th, when Hamas slaughtered 1,200 inno...   \n",
       "0   The US President is working to establish an im...   \n",
       "0   The speaker has addressed the affordability of...   \n",
       "0   The speaker proposes raising the minimum tax r...   \n",
       "0   The president highlights that the economy was ...   \n",
       "\n",
       "                                          source_file  \\\n",
       "0   Speeches/titleedits/state_of_the_union_020723.txt   \n",
       "0   Speeches/titleedits/state_of_the_union_020723.txt   \n",
       "0   Speeches/titleedits/state_of_the_union_020723.txt   \n",
       "0   Speeches/titleedits/state_of_the_union_030724.txt   \n",
       "0   Speeches/titleedits/state_of_the_union_030724.txt   \n",
       "..                                                ...   \n",
       "0   Speeches/titleedits/state_of_the_union_030724.txt   \n",
       "0   Speeches/titleedits/state_of_the_union_030724.txt   \n",
       "0   Speeches/titleedits/state_of_the_union_030724.txt   \n",
       "0   Speeches/titleedits/state_of_the_union_030724.txt   \n",
       "0   Speeches/titleedits/state_of_the_union_030724.txt   \n",
       "\n",
       "                                             contexts  context_precision  \n",
       "0   [Instead of making the wealthy pay their fair ...           0.770833  \n",
       "0   [In the last two years, my administration cut ...           0.833333  \n",
       "0   [And we pay for these investments in our futur...           0.809524  \n",
       "0   [My fellow Americans the issue facing our nati...           0.000000  \n",
       "0   [America’s comeback is building a future of Am...           0.000000  \n",
       "..                                                ...                ...  \n",
       "0   [The deadliest day for the Jewish people since...           0.750000  \n",
       "0   [Israel has an added burden because Hamas hide...           0.000000  \n",
       "0   [Let’s continue increasing Pell Grants for wor...           1.000000  \n",
       "0   [The way to make the tax code fair is to make ...           0.000000  \n",
       "0   [I inherited an economy that was on the brink....           0.000000  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2cf1eed5-c9d2-4c3b-9b21-5ac79affdc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_results.to_csv(\"results/results_ragas_unlabeled_smallruns_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f0535429-a995-44d9-aa1d-db4c7c253449",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdataset = testset_ds.select(range(446, 449))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e7d9071-2ff9-41c3-821e-bf7f3fb0d677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Analyze the political motivations behind GOP proposals regarding Medicare and Social Security sunset provisions.',\n",
       " \"Compare the author's position on cutting Social Security and Medicare to the views of some Republicans, highlighting their differing opinions on these programs and their impact on the American public.\",\n",
       " \"Compare the tone and themes of President Biden's State of the Union Address to that of previous addresses, focusing on his approach to bipartisanship and domestic issues.\"]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempdataset['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb0a5aa-f1b4-4945-957b-9e30a0dd43fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: received warning for the answer where there was no response from the llm, definitely reduced faithfulness score\n",
    "\n",
    "# Results:\n",
    "# Using contexts generated when produced answers from LLM:\n",
    "# new testset_answer_newcontext_flash_pro15.csv result, with contexts_gt (aka contexts generated with ground truth generation) column removed\n",
    "# {'context_precision': 0.4171, 'faithfulness': 0.9167, 'answer_relevancy': 0.6509, 'context_recall': 0.8000}\n",
    "# reran\n",
    "# {'context_precision': 0.4676, 'faithfulness': 1.0000, 'answer_relevancy': 0.6515, 'context_recall': 0.8000}\n",
    "# reran\n",
    "# {'context_precision': 0.5979, 'faithfulness': 1.0000, 'answer_relevancy': 0.6533, 'context_recall': 0.8000}\n",
    "\n",
    "# Compared to using contexts generated for ground truth (probably not correct):\n",
    "# new testset_answer_newcontext_flash_pro15.csv result, using old contexts\n",
    "# {'context_precision': 0.7500, 'faithfulness': 0.7392, 'answer_relevancy': 0.6041, 'context_recall': 1.0000}\n",
    "# reran:\n",
    "# {'context_precision': 0.8500, 'faithfulness': 0.7123, 'answer_relevancy': 0.5934, 'context_recall': 1.0000}\n",
    "# reran:\n",
    "# {'context_precision': 0.7500, 'faithfulness': 0.6556, 'answer_relevancy': 0.5638, 'context_recall': 1.0000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a027af-7dff-483f-97ff-9072e71d7a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation results on metrics:\n",
    "\n",
    "# RAGAS metrics guide: https://docs.ragas.io/en/latest/concepts/metrics/index.html#ragas-metrics\n",
    "# I don't have example ranges to compare anything to, so below is my best guess.\n",
    "\n",
    "# Faithfulness - Measures the factual consistency of the answer to the context based on the question.\n",
    "# 0.9167 - 1.0000 indicates that the LLM is staying true to the facts provided in the context for answering the question.\n",
    "# There is another Faithfulness metric: from ragas.metrics import FaithulnesswithHHEM\n",
    "# This uses a huggingface model to help detect hallucination : https://huggingface.co/vectara/hallucination_evaluation_model\n",
    "# See below for code : {'faithfulness_with_hhem': 0.6319} \n",
    "# This doesn't really agree with the RAGAS faithfulness score... may need to dive in further another time.\n",
    "# Context_precision - Measures how relevant the retrieved context is to the question, conveying the quality of the retrieval pipeline.\n",
    "# At 0.4171 - 0.5979, suggests that the context isn't particularly relevant to the question.\n",
    "# Answer_relevancy - Measures how relevant the answer is to the question.\n",
    "# 0.6509 - 0.6533 seems moderately low, just going off of the number.\n",
    "# Context_recall - Measures the retriever’s ability to retrieve all necessary information required to answer the question.\n",
    "# 0.8 indicates that the llm context is decently good and can typically answer the question or most of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "04f4d426-e499-475e-8459-a497368b8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run, just compare to using contexts_gt column instead of the newer context generated with the answer\n",
    "testset_ds_oldcontext = Dataset.from_pandas(testset_pd.drop(\"contexts\", axis=1).rename(columns={'contexts_old':'contexts'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db7b251-9833-4931-baf2-c575bf900721",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalresult_old2 = evaluate(\n",
    "    testset_ds_oldcontext,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    "    llm = ragas_llm,\n",
    "    embeddings=embeddings, \n",
    "    run_config=run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7170d4-ca68-46b1-a962-3c71093374c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new testset_answer_newcontext_flash_pro15.csv result, using old contexts\n",
    "# {'context_precision': 0.7500, 'faithfulness': 0.7392, 'answer_relevancy': 0.6041, 'context_recall': 1.0000}\n",
    "# reran:\n",
    "# {'context_precision': 0.8500, 'faithfulness': 0.7123, 'answer_relevancy': 0.5934, 'context_recall': 1.0000}\n",
    "# reran:\n",
    "# {'context_precision': 0.7500, 'faithfulness': 0.6556, 'answer_relevancy': 0.5638, 'context_recall': 1.0000}\n",
    "evalresult_old2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb79fac0-ea9d-473f-b33c-02ee96df9559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456a0ae2-f6ae-47e4-bda8-1c66c0104ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAGAS also has an additional Faithfulness with HHEM metric (yes- it is misspelled in their documentation) \n",
    "# that uses a HuggingFace model to detect hallucinations\n",
    "# Note: There's a message on HuggingFace about the token indices sequence length error being normal and an artifact; thus, ignoring the below error\n",
    "# https://huggingface.co/vectara/hallucination_evaluation_model\n",
    "from ragas.metrics import FaithulnesswithHHEM\n",
    "faithfulness_with_hhem = FaithulnesswithHHEM()\n",
    "result_faithfulness_hhem = evaluate(\n",
    "    testset_ds,\n",
    "    metrics=[faithfulness_with_hhem],\n",
    "    llm = ragas_llm,\n",
    "    embeddings=embeddings, \n",
    "    run_config=run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7f158bea-0167-43ab-b4fb-0b5c0bc145c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness_with_hhem': 0.6319}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with context from answer generation:\n",
    "# {'faithfulness_with_hhem': 0.6319}\n",
    "# testing: with context from ground truth/synthetic testset generation\n",
    "# {'faithfulness_with_hhem': 0.5241}\n",
    "# this seems to agree with the RAGAS faithfulness score in that answers seem to be partially made up.\n",
    "result_faithfulness_hhem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7cbe4c-3937-4d48-829a-f0b262698e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "02abe059-1129-4f60-81b7-55cef6b958ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra non-working code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "38993aa7-31ed-438e-96c6-63de9c608016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to use the query_engine in the evaluation \n",
    "# Modeled after this tutorial: https://docs.ragas.io/en/latest/howtos/applications/compare_llms.html\n",
    "\n",
    "# Does not currently work: for some metrics, it is not finding the 'ground_truth' column in the dataset\n",
    "# For other metrics, appears to run but returns the below errors and returns 'nan' for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b983f067-90e5-465a-9014-26fc5593f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start of testing to try and get rag query engine for evaluate\n",
    "def generate_responses(query_engine, test_questions, test_answers):\n",
    "  responses = [query_engine.query(q) for q in test_questions]\n",
    "\n",
    "  answers = []\n",
    "  contexts = []\n",
    "  for r in responses:\n",
    "    answers.append(r.response)\n",
    "    contexts.append([c.node.get_content() for c in r.source_nodes])\n",
    "  dataset_dict = {\n",
    "        \"question\": test_questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "  }\n",
    "  if test_answers is not None:\n",
    "    dataset_dict[\"ground_truth\"] = test_answers\n",
    "  ds = Dataset.from_dict(dataset_dict)\n",
    "  return ds\n",
    "\n",
    "test_questions = testset_pd['question'].values.tolist()\n",
    "test_answers = [[item] for item in testset_pd['answer'].values.tolist()]\n",
    "\n",
    "result_ds = generate_responses(query_engine, test_questions, test_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f75a3-602b-49b8-b269-dab9f3ce817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This evaluate function that uses the query_engine does not return results (nan for all metrics)\n",
    "# Errors (below are repeated many times):\n",
    "# WARNING:ragas.llms.base:n values greater than 1 not support for LlamaIndex LLMs\n",
    "# n values greater than 1 not support for LlamaIndex LLMs\n",
    "# INFO:ragas.llms.base:callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
    "# callbacks not supported for LlamaIndex LLMs, ignoring callbacks\n",
    "# ERROR:ragas.executor:Exception raised in Job[5]: TimeoutError()\n",
    "# Exception raised in Job[5]: TimeoutError()\n",
    "# ERROR:ragas.executor:Exception raised in Job[19]: AttributeError('ChatGoogleGenerativeAI' object has no attribute 'acomplete')\n",
    "# Exception raised in Job[19]: AttributeError('ChatGoogleGenerativeAI' object has no attribute 'acomplete')\n",
    "\n",
    "from ragas.integrations.llama_index import evaluate\n",
    "\n",
    "eval_qe2 = evaluate(\n",
    "    query_engine=query_engine,\n",
    "    dataset=result_ds,\n",
    "    metrics=[faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_utilization],\n",
    "    llm=ragas_llm,\n",
    "    embeddings=embeddings, \n",
    "    run_config=run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "296c8c6d-737d-4233-ae5a-4114597a76f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': nan, 'answer_relevancy': nan, 'context_utilization': nan}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_qe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2c19d1-71a0-40ba-ad28-f689cba75277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research2",
   "language": "python",
   "name": "research2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
