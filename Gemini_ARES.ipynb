{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf756bfd-87bf-4b11-a819-e205176d9075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG with Gemini Flash 1.5 LLM and ARES evaluation\n",
    "# Google Gemini: https://ai.google.dev/gemini-api/docs/models/gemini\n",
    "# ARES: https://github.com/stanford-futuredata/ARES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce7693b8-cf90-4d82-b1ba-89e6d55abcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish RAG pipeline with Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65781f17-9358-4d53-9305-939013e2a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from llama_index.core import Document, VectorStoreIndex, Settings, StorageContext, load_index_from_storage\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "#from llama_index.llms.gemini import Gemini\n",
    "#from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeabfa92-2145-4086-9ba0-d1327a8e2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_markdown(text):\n",
    "  text = text.replace('‚Ä¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66957101-56ea-4dbb-86f9-347a3380ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up local API key\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64b7c6c6-4cac-4b1d-bd60-a409f549759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\") # old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dcd6cf4-f33c-47a0-aa5b-9c236b84822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create document database\n",
    "# using 4 State of the Union speeches, all text from whitehouse.gov briefing room speeches posted online, including a title with the date of the speech\n",
    "# Example from 2024:\n",
    "# https://www.whitehouse.gov/briefing-room/speeches-remarks/2024/03/07/remarks-of-president-joe-biden-state-of-the-union-address-as-prepared-for-delivery-2/\n",
    "sotu = []\n",
    "newfiles = [\"./Speeches/titleedits/state_of_the_union_042921.txt\", \"./Speeches/titleedits/state_of_the_union_030122.txt\", \"./Speeches/titleedits/state_of_the_union_020723.txt\", \"./Speeches/titleedits/state_of_the_union_030724.txt\"]\n",
    "for i in newfiles:\n",
    "    with open(i) as file:\n",
    "        for line in file:\n",
    "            nl = line.rstrip()\n",
    "            if nl != '':\n",
    "                sotu.append(nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9c33d54-9e37-4e1d-834c-669026fe4cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [Document(text=line) for line in sotu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4cadba0-1efd-47a7-849c-586713f3fc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='6b97bcac-79d6-4bf9-a0ed-1b9ec8a23f5f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='May God protect our troops.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of a loaded Document line\n",
    "documents[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8534e02-a129-42c1-871f-31ab6919ddf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Set up the faiss index\n",
    "d = 768 # dimensions of the input vector of the embedding model that we're going to use; in this case, the google embedding model\n",
    "faiss_index = faiss.IndexFlatL2(d)\n",
    "print(faiss_index.is_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29482b9f-dbea-4e8e-bdb3-1dbc262b7324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = Gemini(model=\"models/gemini-1.5-flash\", api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab6ce235-d506-4151-9970-d4a34b52a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the embeddings\n",
    "doc_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\") # optional: task_type=\"RETRIEVAL_DOCUMENT\"\n",
    "#doc_embeddings = GeminiEmbedding(model=\"models/text-embedding-004\")\n",
    "Settings.embed_model = doc_embeddings\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5e63d9f-afda-4661-a477-d9192d710779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Waddle On Over! üêß\n",
      "\n",
      "You're invited to celebrate [Child's Name]'s 2nd Birthday!\n",
      "\n",
      "Join us for a penguin-tastic party filled with fun, games, and treats!\n",
      "\n",
      "**Date:** [Date of party]\n",
      "**Time:** [Time of party]\n",
      "**Location:** [Location of party]\n",
      "\n",
      "**Dress Code:** Come dressed in your best penguin attire! üêß\n",
      "\n",
      "**RSVP:** Please let us know if you can join the fun by [RSVP date]\n",
      "\n",
      "We can't wait to celebrate with you!\n",
      "\n",
      "**[Contact information]** \n",
      "\n",
      "**P.S.**  Please note that this is a child-friendly event. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test llm\n",
    "#response = llm.complete(\"Write the text for an invitation for a two year old's penguin themed birthday party.\")\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfe61b42-b268-4f15-a8cc-6ee6130aff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment for when you need to re-embed and vectorize documents\n",
    "## otherwise, doing local loading below\n",
    "#vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "#storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "#index = VectorStoreIndex.from_documents(\n",
    "#    documents, storage_context=storage_context, show_progress=True\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efff8caa-8a55-441a-9706-12e0f27487f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save index to disk\n",
    "#index.storage_context.persist()\n",
    "#index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c032469-b39e-47bf-a328-d884a9e717f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index from disk\n",
    "vector_store = FaissVectorStore.from_persist_dir(\"./storage\")\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store, persist_dir=\"./storage\"\n",
    ")\n",
    "# index id 'cef7ae30-ff1e-404a-bce6-85d59ca4b376' uses the speeches with a title that includes the date it was given\n",
    "index = load_index_from_storage(storage_context=storage_context, index_id='cef7ae30-ff1e-404a-bce6-85d59ca4b376')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "833ae491-6e3e-497e-af35-f2823c7da9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up query and chat engines\n",
    "query_engine = index.as_query_engine(similarity_top_k=10)\n",
    "chat_engine = index.as_chat_engine(similarity_top_k=10, chat_mode='context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef3b0844-f59f-4d12-856e-d2f28fa05857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amber/anaconda3/envs/research2/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseChatModel.predict_messages` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Example query and response\n",
    "query = \"What does the President say about his administration's first 100 days and covid-19?\"\n",
    "response = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d0bee64-2b5d-4ae3-8b54-fda538ad476c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The President states that America has made great progress in fighting the pandemic, exceeding his goal of administering 100 million COVID-19 vaccine shots in 100 days by providing over 220 million shots.  He views this as one of the greatest logistical achievements in the country's history. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34897696-e3d2-4a40-b741-d839cc308931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to get ARES to work with Gemini and our local RAG setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2984ff52-f184-49ec-a3d8-8124c8667a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vLLM not imported.\n"
     ]
    }
   ],
   "source": [
    "from ares import ARES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4ce3cc2-a413-4ce2-8891-593347deddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ues_idp_config = {\n",
    "    \"in_domain_prompts_dataset\": \"ARES_files/nq_few_shot_prompt_for_judge_scoring.tsv\",\n",
    "    \"unlabeled_evaluation_set\": \"ARES_files/nq_unlabeled_output.tsv\", \n",
    "    \"model_choice\" : \"models/gemini-1.5-flash\",\n",
    "    \"request_delay\" : 60\n",
    "} \n",
    "\n",
    "ares = ARES(ues_idp=ues_idp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0957b957-09c2-4b0d-bda1-a87945225f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572ffb8ebe9b44f9859a3416301a274d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating large subset with models/gemini-1.5-flash:   0%|          | 0/6189 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configured gemini for context relevance\n",
      "Attempt 1 failed with error: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['Content']\"\n",
      "Attempt 2 failed with error: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['Content']\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/ARES/ares/RAG_Automatic_Evaluation/Evaluation_Functions.py:226\u001b[0m, in \u001b[0;36mfew_shot_context_relevance_scoring_gemini\u001b[0;34m(system_prompt, query, document, model_choice, query_id, debug_mode, request_delay, failed_extraction_count, few_shot_examples)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# typically model should be 'models/gemini-1.5-flash'\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGenerativeModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_choice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_instruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_prompt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m#openai.chat.completions.create(\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m#                    model=model_choice,\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m#                    messages=messages\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m#                )    \u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/research2/lib/python3.11/site-packages/google/generativeai/generative_models.py:305\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontents must not be empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 305\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request\u001b[38;5;241m.\u001b[39mcontents \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m request\u001b[38;5;241m.\u001b[39mcontents[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mrole:\n",
      "File \u001b[0;32m~/anaconda3/envs/research2/lib/python3.11/site-packages/google/generativeai/generative_models.py:154\u001b[0m, in \u001b[0;36mGenerativeModel._prepare_request\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config)\u001b[0m\n\u001b[1;32m    152\u001b[0m     tool_config \u001b[38;5;241m=\u001b[39m content_types\u001b[38;5;241m.\u001b[39mto_tool_config(tool_config)\n\u001b[0;32m--> 154\u001b[0m contents \u001b[38;5;241m=\u001b[39m \u001b[43mcontent_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m generation_config \u001b[38;5;241m=\u001b[39m generation_types\u001b[38;5;241m.\u001b[39mto_generation_config_dict(generation_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/research2/lib/python3.11/site-packages/google/generativeai/types/content_types.py:295\u001b[0m, in \u001b[0;36mto_contents\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m contents \u001b[38;5;241m=\u001b[39m [\u001b[43mto_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m contents\n",
      "File \u001b[0;32m~/anaconda3/envs/research2/lib/python3.11/site-packages/google/generativeai/types/content_types.py:253\u001b[0m, in \u001b[0;36mto_content\u001b[0;34m(content)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, Mapping):\n\u001b[0;32m--> 253\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, protos\u001b[38;5;241m.\u001b[39mContent):\n",
      "File \u001b[0;32m~/anaconda3/envs/research2/lib/python3.11/site-packages/google/generativeai/types/content_types.py:138\u001b[0m, in \u001b[0;36m_convert_dict\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to determine the intended type of the `dict`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor `Content`, a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m key is expected. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor `Part`, either an \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline_data\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m key is expected. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor `Blob`, both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmime_type\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keys are expected. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHowever, the provided dictionary has the following keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(d\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m     )\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['Content']\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mares\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mues_idp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[0;32m~/ARES/ares/ares.py:153\u001b[0m, in \u001b[0;36mARES.ues_idp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mues_idp\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    150\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m    Executes the UES IDP configuration.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mues_idp_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mues_idp_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ARES/ares/ues_idp.py:292\u001b[0m, in \u001b[0;36mues_idp_config\u001b[0;34m(in_domain_prompts_dataset, unlabeled_evaluation_set, context_relevance_system_prompt, answer_relevance_system_prompt, answer_faithfulness_system_prompt, debug_mode, documents, model_choice, vllm, host_url, request_delay)\u001b[0m\n\u001b[1;32m    287\u001b[0m in_domain_prompts_dataset, unlabeled_evaluation_set, documents \u001b[38;5;241m=\u001b[39m validate_inputs(\n\u001b[1;32m    288\u001b[0m     vllm, host_url, in_domain_prompts_dataset, unlabeled_evaluation_set, documents\n\u001b[1;32m    289\u001b[0m )\n\u001b[1;32m    291\u001b[0m \u001b[38;5;66;03m# Evaluate the documents and get the scores\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m context_relevance_scores, answer_relevance_scores, answer_faithfulness_scores \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43munlabeled_evaluation_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_domain_prompts_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_relevance_system_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer_relevance_system_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer_faithfulness_system_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_choice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;66;03m# Create a DataFrame to store the results\u001b[39;00m\n\u001b[1;32m    299\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContext_Relevance_Score\u001b[39m\u001b[38;5;124m'\u001b[39m: context_relevance_scores,\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnswer_Relevance_Score\u001b[39m\u001b[38;5;124m'\u001b[39m: answer_relevance_scores,\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnswer_Faithfulness_Score\u001b[39m\u001b[38;5;124m'\u001b[39m: answer_faithfulness_scores\n\u001b[1;32m    303\u001b[0m })\n",
      "File \u001b[0;32m~/ARES/ares/ues_idp.py:242\u001b[0m, in \u001b[0;36mevaluate_documents\u001b[0;34m(unlabeled_evaluation_set, in_domain_prompts_dataset, context_relevance_system_prompt, answer_relevance_system_prompt, answer_faithfulness_system_prompt, model_choice, debug_mode, request_delay, vllm, host_url, documents)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mdocuments, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating large subset with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_choice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m unlabeled_evaluation_set[:documents]\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m--> 242\u001b[0m         context_score, answer_relevance_score, answer_faithfulness_score \u001b[38;5;241m=\u001b[39m \u001b[43mscore_row\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_domain_prompts_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_relevance_system_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer_relevance_system_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer_faithfulness_system_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_choice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQuery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m         context_relevance_scores\u001b[38;5;241m.\u001b[39mappend(context_score)\n\u001b[1;32m    246\u001b[0m         answer_relevance_scores\u001b[38;5;241m.\u001b[39mappend(answer_relevance_score)\n",
      "File \u001b[0;32m~/ARES/ares/ues_idp.py:172\u001b[0m, in \u001b[0;36mscore_row\u001b[0;34m(row, in_domain_prompts_dataset, context_relevance_system_prompt, answer_relevance_system_prompt, answer_faithfulness_system_prompt, model_choice, query_id, debug_mode, request_delay, vllm, host_url)\u001b[0m\n\u001b[1;32m    169\u001b[0m     context_score \u001b[38;5;241m=\u001b[39m few_shot_context_relevance_scoring_claude(\n\u001b[1;32m    170\u001b[0m         context_relevance_system_prompt, query, document, model_choice, query_id, debug_mode, request_delay, failed_extraction_count, in_domain_prompts_dataset)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_choice:\n\u001b[0;32m--> 172\u001b[0m     context_score \u001b[38;5;241m=\u001b[39m \u001b[43mfew_shot_context_relevance_scoring_gemini\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext_relevance_system_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_choice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfailed_extraction_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_domain_prompts_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     context_score \u001b[38;5;241m=\u001b[39m few_shot_context_relevance_scoring_togetherai(\n\u001b[1;32m    176\u001b[0m         context_relevance_system_prompt, query, document, model_choice, query_id, debug_mode, request_delay, failed_extraction_count, in_domain_prompts_dataset)\n",
      "File \u001b[0;32m~/ARES/ares/RAG_Automatic_Evaluation/Evaluation_Functions.py:258\u001b[0m, in \u001b[0;36mfew_shot_context_relevance_scoring_gemini\u001b[0;34m(system_prompt, query, document, model_choice, query_id, debug_mode, request_delay, failed_extraction_count, few_shot_examples)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attempt \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m4\u001b[39m:  \u001b[38;5;66;03m# Only print the error message if not on the last attempt\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed with error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 258\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m60\u001b[39m)  \u001b[38;5;66;03m# Sleep for 60 seconds before retrying\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll attempts failed. Last error was:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = ares.ues_idp()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c815504d-3470-4047-9e4f-35332844fa0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research2",
   "language": "python",
   "name": "research2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
