{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf756bfd-87bf-4b11-a819-e205176d9075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG with Gemini Flash 1.5 LLM and ARES evaluation\n",
    "# Google Gemini: https://ai.google.dev/gemini-api/docs/models/gemini\n",
    "# ARES: https://github.com/stanford-futuredata/ARES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce7693b8-cf90-4d82-b1ba-89e6d55abcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish RAG pipeline with Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65781f17-9358-4d53-9305-939013e2a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from llama_index.core import Document, VectorStoreIndex, Settings, StorageContext, load_index_from_storage\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "#from llama_index.llms.gemini import Gemini\n",
    "#from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeabfa92-2145-4086-9ba0-d1327a8e2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66957101-56ea-4dbb-86f9-347a3380ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up local API key\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b7c6c6-4cac-4b1d-bd60-a409f549759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\") # old function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dcd6cf4-f33c-47a0-aa5b-9c236b84822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create document database\n",
    "# using 4 State of the Union speeches, all text from whitehouse.gov briefing room speeches posted online, including a title with the date of the speech\n",
    "# Example from 2024:\n",
    "# https://www.whitehouse.gov/briefing-room/speeches-remarks/2024/03/07/remarks-of-president-joe-biden-state-of-the-union-address-as-prepared-for-delivery-2/\n",
    "sotu = []\n",
    "newfiles = [\"./Speeches/titleedits/state_of_the_union_042921.txt\", \"./Speeches/titleedits/state_of_the_union_030122.txt\", \"./Speeches/titleedits/state_of_the_union_020723.txt\", \"./Speeches/titleedits/state_of_the_union_030724.txt\"]\n",
    "for i in newfiles:\n",
    "    with open(i) as file:\n",
    "        for line in file:\n",
    "            nl = line.rstrip()\n",
    "            if nl != '':\n",
    "                sotu.append(nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9c33d54-9e37-4e1d-834c-669026fe4cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [Document(text=line) for line in sotu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4cadba0-1efd-47a7-849c-586713f3fc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='02f5ebd8-b938-49aa-adfc-4dc668d30ad1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='May God protect our troops.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of a loaded Document line\n",
    "documents[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8534e02-a129-42c1-871f-31ab6919ddf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Set up the faiss index\n",
    "d = 768 # dimensions of the input vector of the embedding model that we're going to use; in this case, the google embedding model\n",
    "faiss_index = faiss.IndexFlatL2(d)\n",
    "print(faiss_index.is_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29482b9f-dbea-4e8e-bdb3-1dbc262b7324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = Gemini(model=\"models/gemini-1.5-flash\", api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab6ce235-d506-4151-9970-d4a34b52a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the embeddings\n",
    "doc_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\") # optional: task_type=\"RETRIEVAL_DOCUMENT\"\n",
    "#doc_embeddings = GeminiEmbedding(model=\"models/text-embedding-004\")\n",
    "Settings.embed_model = doc_embeddings\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5e63d9f-afda-4661-a477-d9192d710779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test llm\n",
    "#response = llm.complete(\"Write the text for an invitation for a two year old's penguin themed birthday party.\")\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfe61b42-b268-4f15-a8cc-6ee6130aff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment for when you need to re-embed and vectorize documents\n",
    "## otherwise, doing local loading below\n",
    "#vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "#storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "#index = VectorStoreIndex.from_documents(\n",
    "#    documents, storage_context=storage_context, show_progress=True\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efff8caa-8a55-441a-9706-12e0f27487f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save index to disk\n",
    "#index.storage_context.persist()\n",
    "#index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c032469-b39e-47bf-a328-d884a9e717f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index from disk\n",
    "vector_store = FaissVectorStore.from_persist_dir(\"./storage\")\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store, persist_dir=\"./storage\"\n",
    ")\n",
    "# index id 'cef7ae30-ff1e-404a-bce6-85d59ca4b376' uses the speeches with a title that includes the date it was given\n",
    "index = load_index_from_storage(storage_context=storage_context, index_id='cef7ae30-ff1e-404a-bce6-85d59ca4b376')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "833ae491-6e3e-497e-af35-f2823c7da9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up query and chat engines\n",
    "query_engine = index.as_query_engine(similarity_top_k=10)\n",
    "chat_engine = index.as_chat_engine(similarity_top_k=10, chat_mode='context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b0844-f59f-4d12-856e-d2f28fa05857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query and response\n",
    "#query = \"What does the President say about his administration's first 100 days and covid-19?\"\n",
    "#response = query_engine.query(query) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d0bee64-2b5d-4ae3-8b54-fda538ad476c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The President is proud of his administration's progress in fighting the pandemic, citing the successful rollout of COVID-19 vaccines. He highlights that they have surpassed their goal of administering 100 million vaccine shots in 100 days, reaching over 220 million shots. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34897696-e3d2-4a40-b741-d839cc308931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to get ARES to work with Gemini and our local RAG setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2984ff52-f184-49ec-a3d8-8124c8667a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vLLM not imported.\n"
     ]
    }
   ],
   "source": [
    "from ares import ARES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4ce3cc2-a413-4ce2-8891-593347deddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ues_idp_config = {\n",
    "    \"in_domain_prompts_dataset\": \"ARES_files/nq_few_shot_prompt_for_judge_scoring.tsv\",\n",
    "    \"unlabeled_evaluation_set\": \"ARES_files/nq_unlabeled_output.tsv\", \n",
    "    \"model_choice\" : \"models/gemini-1.5-flash\",\n",
    "    \"request_delay\" : 60,\n",
    "    \"documents\" : 3\n",
    "} \n",
    "\n",
    "ares = ARES(ues_idp=ues_idp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0957b957-09c2-4b0d-bda1-a87945225f91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a67a3e9b7a47168bcb0e97f7c05f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating large subset with models/gemini-1.5-flash:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configured gemini for context relevance\n",
      "Testing response.text\n",
      "[[Yes]] \n",
      "\n",
      "Testing candidates\n",
      "['[[Yes]] \\n']\n",
      "configured gemini for answer relevance\n",
      "Testing response.text\n",
      "[[Yes]]\n",
      "\n",
      "configured gemini for answer faithfulness\n",
      "Testing response.text\n",
      "[[Yes]]\n",
      "\n",
      "configured gemini for context relevance\n",
      "Testing response.text\n",
      "[[Yes]]\n",
      "\n",
      "Testing candidates\n",
      "['[[Yes]]\\n']\n",
      "configured gemini for answer relevance\n",
      "Testing response.text\n",
      "[[Yes]]\n",
      "\n",
      "configured gemini for answer faithfulness\n",
      "Testing response.text\n",
      "[[Yes]]\n",
      "\n",
      "configured gemini for context relevance\n",
      "Attempt 1 failed with error: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked.\n",
      "Attempt 2 failed with error: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked.\n",
      "Attempt 3 failed with error: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked.\n",
      "Attempt 4 failed with error: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked.\n",
      "All attempts failed. Last error was: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked.\n",
      "Number of times did not extract Yes or No: 0\n",
      "{'Context Relevance Scores': 0.667, 'Answer Faithfulness Scores': 0.667, 'Answer Relevance Scores': 0.667}\n"
     ]
    }
   ],
   "source": [
    "results = ares.ues_idp()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c815504d-3470-4047-9e4f-35332844fa0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Context Relevance Scores': 0.667,\n",
       " 'Answer Faithfulness Scores': 0.667,\n",
       " 'Answer Relevance Scores': 0.667}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results # exact scores repeated on second run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ca8ee8b-e105-436f-8f52-692c736bbeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopped here: Need to generate synthetic question/answer/document file\n",
    "\n",
    "# document refers to a line in a document_filepath_file; unsure if this setup of 1 large document per line will work\n",
    "synth_config = { \n",
    "    \"document_filepaths\": [\"Speeches/titleedits/Speeches_Docs6.tsv\"], # requires tsv file...\n",
    "    \"few_shot_prompt_filename\": \"datasets/manual_dataset_complete_ares_synthetic.tsv\",\n",
    "    \"synthetic_queries_filenames\": [\"results/synthetic_results.tsv\"],\n",
    "    \"model_choice\": \"models/gemini-1.5-flash\", # ex: \"google/flan-t5-xxl\" \n",
    "    \"documents_sampled\": 4, # was 10000\n",
    "    \"api_model\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57f5c628-84b7-4222-bd8d-5499dd1b585c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Saving synthetic queries to:  ['results/synthetic_results.tsv']\n",
      "========================================\n",
      "\n",
      "=======================================\n",
      "| Starting Synthetic Query Generation |\n",
      "=======================================\n",
      "\n",
      "Generating positive queries for the first 2 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating positive synthetic queries for documents 0 to 2...:   0%|                              | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configured gemini for synthetic query generation\n",
      "Testing response.text\n",
      "What is the date of the State of the Union Address mentioned in the document? \n",
      "\n",
      "Testing response.text\n",
      "What is the date of the State of the Union Address mentioned in the document? \n",
      "\n",
      "Testing response.text\n",
      "What is the date of President Biden's State of the Union Address mentioned in the document? \n",
      "\n",
      "Testing response.text\n",
      "What are the opening remarks of President Biden's 2024 State of the Union Address? \n",
      "\n",
      "Testing response.text\n",
      "What is the date of the State of the Union Address mentioned in the document? \n",
      "\n",
      "Testing response.text\n",
      "What is the date of the State of the Union Address mentioned in the document? \n",
      "\n",
      "Testing response.text\n",
      "What is the date of the State of the Union Address mentioned in the document? \n",
      "\n",
      "Testing response.text\n",
      "What is the main message that President Biden conveyed in his 2024 State of the Union address? \n",
      "\n",
      "Testing response.text\n",
      "What is the date of the State of the Union Address mentioned in the document? \n",
      "\n",
      "Testing response.text\n",
      "What is the date of the State of the Union Address mentioned in the document? \n",
      "\n",
      "Testing response.text\n",
      "What is the purpose of President Biden's 2024 State of the Union Address? \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating positive synthetic queries for documents 0 to 2...:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 1/4 [00:06<00:18,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing response.text\n",
      "What was the context of the 1941 State of the Union address delivered by President Franklin Roosevelt? \n",
      "\n",
      "configured gemini for synthetic query generation\n",
      "Testing response.text\n",
      "What is the date of the State of the Union Address mentioned in the document? \n",
      "\n",
      "Testing response.text\n",
      "What is the date of the State of the Union Address mentioned in the text? \n",
      "\n",
      "Testing response.text\n",
      "What is the purpose of President Biden's 2024 State of the Union Address? \n",
      "\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.95\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.05\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.25\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.5\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.95\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.05\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.25\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.5\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating positive synthetic queries for documents 0 to 2...:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 2/4 [00:12<00:12,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.95\n",
      "configured gemini for synthetic query generation\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.05\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.25\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.5\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.95\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.05\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.25\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.5\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.95\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.05\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.25\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.5\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating positive synthetic queries for documents 0 to 2...:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 3/4 [00:18<00:06,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.95\n",
      "configured gemini for synthetic query generation\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.05\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.25\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.5\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.95\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.05\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.25\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.5\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.95\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.05\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.25\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.5\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating positive synthetic queries for documents 0 to 2...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:23<00:00,  5.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating synthetic queries: 429 Resource has been exhausted (e.g. check quota).\n",
      "Failed to generate synthetic queries after 5 attempts for percentile 0.95\n",
      "Total queries generated before filtering: 15\n",
      "Total queries after length filtering: 15\n",
      "Total queries after deduplication: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings...:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                            | 1/2 [00:00<00:00, 3057.07it/s]\n"
     ]
    },
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ares \u001b[38;5;241m=\u001b[39m ARES(synthetic_query_generator\u001b[38;5;241m=\u001b[39msynth_config)\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mares\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_synthetic_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# stopped here, need to debug/edit to work with Gemini\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[0;32m~/ARES/ares/ares.py:127\u001b[0m, in \u001b[0;36mARES.generate_synthetic_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping synthetic generator configuration due to missing parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[43msynthetic_generator_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthetic_query_generator_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ARES/ares/synthetic_generator.py:125\u001b[0m, in \u001b[0;36msynthetic_generator_config\u001b[0;34m(document_filepaths, few_shot_prompt_filename, synthetic_queries_filenames, documents_sampled, model_choice, api_model, clean_documents, regenerate_synth_questions, percentiles, question_temperatures, regenerate_answers, number_of_negatives_added_ratio, lower_bound_for_negatives, number_of_contradictory_answers_added_ratio, number_of_positives_added_ratio, regenerate_embeddings, synthetic_query_prompt, synthetic_valid_answer_prompt, synthetic_contradictory_answer_prompt)\u001b[0m\n\u001b[1;32m    103\u001b[0m answer_gen_few_shot_examples, length_of_fewshot_prompt_answer_gen \u001b[38;5;241m=\u001b[39m generate_few_shot_prompts(\n\u001b[1;32m    104\u001b[0m     few_shot_prompt_filename, for_fever_dataset, for_wow_dataset\n\u001b[1;32m    105\u001b[0m )\n\u001b[1;32m    107\u001b[0m synthetic_queries_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfew_shot_examples\u001b[39m\u001b[38;5;124m'\u001b[39m: few_shot_examples,\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_of_fewshot_prompt\u001b[39m\u001b[38;5;124m'\u001b[39m: length_of_fewshot_prompt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower_bound_for_negatives\u001b[39m\u001b[38;5;124m'\u001b[39m: lower_bound_for_negatives,\n\u001b[1;32m    123\u001b[0m }\n\u001b[0;32m--> 125\u001b[0m \u001b[43mgenerate_synthetic_queries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynthetic_queries_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m synthetic_answers_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregenerate_answers\u001b[39m\u001b[38;5;124m'\u001b[39m: regenerate_answers,\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer_gen_few_shot_examples\u001b[39m\u001b[38;5;124m'\u001b[39m: answer_gen_few_shot_examples,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregenerate_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m: regenerate_embeddings\n\u001b[1;32m    145\u001b[0m }\n\u001b[1;32m    147\u001b[0m Generate_Synthetic_Answers(synthetic_queries_filename, synthetic_answers_config)\n",
      "File \u001b[0;32m~/ARES/ares/LLM_as_a_Judge_Adaptation/Generate_Synthetic_Queries_and_Answers.py:490\u001b[0m, in \u001b[0;36mgenerate_synthetic_queries\u001b[0;34m(documents, settings)\u001b[0m\n\u001b[1;32m    487\u001b[0m second_half_documents \u001b[38;5;241m=\u001b[39m documents\u001b[38;5;241m.\u001b[39mtail(num_documents \u001b[38;5;241m-\u001b[39m half_num_documents)\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating positive queries for the first \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(first_half_documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m documents...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 490\u001b[0m positive_queries_df \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_positive_synthetic_queries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_half_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m num_to_sample \u001b[38;5;241m=\u001b[39m half_num_documents\n\u001b[1;32m    493\u001b[0m positive_queries_for_answers_df \u001b[38;5;241m=\u001b[39m positive_queries_df\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39mnum_to_sample, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/ARES/ares/LLM_as_a_Judge_Adaptation/Generate_Synthetic_Queries_and_Answers.py:377\u001b[0m, in \u001b[0;36mgenerate_positive_synthetic_queries\u001b[0;34m(documents, settings, chunk_size)\u001b[0m\n\u001b[1;32m    374\u001b[0m synthetic_queries_df \u001b[38;5;241m=\u001b[39m synthetic_queries_df\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msynthetic_query\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal queries after deduplication: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(synthetic_queries_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 377\u001b[0m document_index \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m synthetic_queries_df \u001b[38;5;241m=\u001b[39m filter_synthetic_queries(synthetic_queries_df, document_index)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal queries after filtering: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(synthetic_queries_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ARES/ares/LLM_as_a_Judge_Adaptation/Filter_Synthetic_Queries.py:70\u001b[0m, in \u001b[0;36mgenerate_index\u001b[0;34m(dataframe)\u001b[0m\n\u001b[1;32m     67\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mpandas(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating embeddings...\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39mdataframe\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Generate embeddings for each document\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdataframe\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocument\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext-embedding-ada-002\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Filter out rows where the embedding length is not 1536\u001b[39;00m\n\u001b[1;32m     73\u001b[0m dataframe \u001b[38;5;241m=\u001b[39m dataframe[dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1536\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/research2/lib/python3.11/site-packages/tqdm/std.py:917\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/research2/lib/python3.11/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/research2/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/research2/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/envs/research2/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/research2/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/research2/lib/python3.11/site-packages/tqdm/std.py:912\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ARES/ares/LLM_as_a_Judge_Adaptation/Filter_Synthetic_Queries.py:70\u001b[0m, in \u001b[0;36mgenerate_index.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     67\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mpandas(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating embeddings...\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39mdataframe\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Generate embeddings for each document\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dataframe[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mprogress_apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext-embedding-ada-002\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Filter out rows where the embedding length is not 1536\u001b[39;00m\n\u001b[1;32m     73\u001b[0m dataframe \u001b[38;5;241m=\u001b[39m dataframe[dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1536\u001b[39m]\n",
      "File \u001b[0;32m~/ARES/ares/LLM_as_a_Judge_Adaptation/Filter_Synthetic_Queries.py:33\u001b[0m, in \u001b[0;36mget_embedding\u001b[0;34m(text, model)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embedding\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m, model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-ada-002\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    Generates an embedding for the given text using the specified model.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    list: A list representing the embedding of the input text.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Replace newline characters with spaces\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/research2/lib/python3.11/site-packages/openai/_client.py:98\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m     96\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "ares = ARES(synthetic_query_generator=synth_config)\n",
    "results = ares.generate_synthetic_data() # stopped here, need to debug/edit to work with Gemini; next is embeddings error below\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "027370c9-e2af-48a3-96e2-edc9755cda26",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Context_Relevance_Label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/research2/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Context_Relevance_Label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 15\u001b[0m\n\u001b[1;32m      5\u001b[0m synth_config \u001b[38;5;241m=\u001b[39m { \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument_filepaths\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeeches/titleedits/Speeches_Docs6.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;66;03m# requires tsv file...\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfew_shot_prompt_filename\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/manual_dataset_complete_ares_synthetic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_model\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\u001b[38;5;66;03m# was 10000\u001b[39;00m\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     14\u001b[0m ares \u001b[38;5;241m=\u001b[39m ARES(synthetic_query_generator\u001b[38;5;241m=\u001b[39msynth_config)\n\u001b[0;32m---> 15\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mares\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_synthetic_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# stopped here, need to edit to work with Gemini\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[0;32m~/ARES/ares/ares.py:127\u001b[0m, in \u001b[0;36mARES.generate_synthetic_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping synthetic generator configuration due to missing parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[43msynthetic_generator_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthetic_query_generator_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ARES/ares/synthetic_generator.py:95\u001b[0m, in \u001b[0;36msynthetic_generator_config\u001b[0;34m(document_filepaths, few_shot_prompt_filename, synthetic_queries_filenames, documents_sampled, model_choice, api_model, clean_documents, regenerate_synth_questions, percentiles, question_temperatures, regenerate_answers, number_of_negatives_added_ratio, lower_bound_for_negatives, number_of_contradictory_answers_added_ratio, number_of_positives_added_ratio, regenerate_embeddings, synthetic_query_prompt, synthetic_valid_answer_prompt, synthetic_contradictory_answer_prompt)\u001b[0m\n\u001b[1;32m     87\u001b[0m     synthetic_valid_answer_prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are given a document and a query. Determine if the query is supported or refuted by the information in the document. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer with either \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUPPORTS\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREFUTES\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m based on the content of the document.  Return only one correct answer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDo not return multiple answers, labels, or additional text.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m     )\n\u001b[1;32m     93\u001b[0m documents \u001b[38;5;241m=\u001b[39m load_documents(document_filepath, clean_documents, documents_sampled)\n\u001b[0;32m---> 95\u001b[0m few_shot_examples, length_of_fewshot_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mload_few_shot_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfew_shot_prompt_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfor_fever_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfor_wow_dataset\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m few_shot_examples_for_contradictory_answers \u001b[38;5;241m=\u001b[39m generate_contradictory_answers(\n\u001b[1;32m    100\u001b[0m     few_shot_prompt_filename, for_fever_dataset, for_wow_dataset\n\u001b[1;32m    101\u001b[0m )\n\u001b[1;32m    103\u001b[0m answer_gen_few_shot_examples, length_of_fewshot_prompt_answer_gen \u001b[38;5;241m=\u001b[39m generate_few_shot_prompts(\n\u001b[1;32m    104\u001b[0m     few_shot_prompt_filename, for_fever_dataset, for_wow_dataset\n\u001b[1;32m    105\u001b[0m )\n",
      "File \u001b[0;32m~/ARES/ares/LLM_as_a_Judge_Adaptation/Generate_Synthetic_Queries_and_Answers.py:188\u001b[0m, in \u001b[0;36mload_few_shot_prompt\u001b[0;34m(few_shot_prompt_filename, for_fever_dataset, for_wow_dataset)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03mLoads and processes a few-shot prompt from a TSV file.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m    tuple[str, int]: A tuple containing the few-shot examples as a string and the length of the few-shot prompt.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    187\u001b[0m few_shot_prompt \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(few_shot_prompt_filename, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 188\u001b[0m few_shot_prompt \u001b[38;5;241m=\u001b[39m few_shot_prompt[\u001b[43mfew_shot_prompt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mContext_Relevance_Label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[[Yes]]\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m few_shot_prompt:\n\u001b[1;32m    191\u001b[0m     few_shot_prompt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuery\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m few_shot_prompt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/research2/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/research2/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Context_Relevance_Label'"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4437ef8e-f8f2-4428-b5d3-a4a5654c444e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research2",
   "language": "python",
   "name": "research2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
